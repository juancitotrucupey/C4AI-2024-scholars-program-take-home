# Description
As part of my application to the [Cohere Scholars program for 2024](https://txt.cohere.com/c4ai-scholars-program/) I have taken the tasks of diving into BERT encoders, in particular, into encoders for semantic embeddings.

- [Here](https://github.com/juancitotrucupey/C4AI-2024-scholars-program-take-home/blob/main/take_home_assignment.ipynb) you can find the assignement given by C4AI.
- [Here](https://github.com/juancitotrucupey/C4AI-2024-scholars-program-take-home/blob/main/my_solution.ipynb) you can find my solution to the assignment.

My solution has explanations for the following:
- The [BERT encoder implementation found in the HuggingFace python library](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert)
- The [sentence transformers methodology for training encoders for semantic embeddings](https://arxiv.org/abs/1908.10084)
- [Methodologies for unsupervised learning of semantic embeddings using BERT encoders](https://www.sbert.net/examples/unsupervised_learning/README.html) 
