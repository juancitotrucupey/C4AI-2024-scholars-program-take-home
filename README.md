# Description
As part of my application to the [Cohere Scholars programm for 2024](https://txt.cohere.com/c4ai-scholars-program/) I have taken the tasks of diving into BERT encoders, in particular, into encoders for semantic embeddings.

- [Here](https://github.com/juancitotrucupey/C4AI-2024-scholars-program-take-home/blob/main/take_home_assignment.ipynb) you can find the assignement given by C4AI.
- [Here](https://github.com/juancitotrucupey/C4AI-2024-scholars-program-take-home/blob/main/my_solution.ipynb) you can find my solution to the assignement.

My solution has explanations on:
- The [BERT encoder implementation found in the HuggingFace python library](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert)
- The [sentence trasnformers methodology for training encoders for semantic embeddings](https://arxiv.org/abs/1908.10084)
- [Methodologies for unsuipervised learning of semantic embeddings using BERT encoders](https://www.sbert.net/examples/unsupervised_learning/README.html) 

## Update
Unfortunately I have not been chosen to participate in the Cohere Scholars programm for 2024 :( , however, I had the opportunity to deppen my knowledge in semantic embeddigns from BERT encoders. 
